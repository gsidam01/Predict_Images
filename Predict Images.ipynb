{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Image Prediction\n",
    "- I wrote a similar project for a class in college, but our data was a set of hand-drawn 8s and 9s.\n",
    "- In college, my team would frequently sail at MIT, so we would use their boathouse cameras to determine the day's conditions.\n",
    "- I have combined the underlying principles of my project with the data from the MIT cameras to predict whether there is a person on the dock or a sailboat in the water in any given still image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Try different models besides just Random Forrest\n",
    "- Generate signfiicantly more training data - currently about 50 examples\n",
    "- Slightly reduce inline comment and provide more context at beginning of blocks\n",
    "- Code method for reducing images from their original size to fit in 320x320 pixels (all images end up as 320x180), currently done manually after downloading them\n",
    "- Determine more \"target columns\" and then make them variables//remove hard-coding in body of code\n",
    "- Use preprocess_image() elsewhere if possible, maybe have it defined earlier\n",
    "- Streamline code where possible - see what an LLM will say about it?\n",
    "- Evaluate any time/space complexity hot spots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Paths, Hard-Coded Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "photo_folder_path = \"./data/20230912/\"\n",
    "data_file_path    = \"./MIT Sailing Camera Data.xlsx\"\n",
    "data_sheet_name   = \"S Data 12 Sep 23\"\n",
    "data_labels_ind   = \"Time https://sailing.mit.edu/eyesee/\"\n",
    "data_labels_to_use = [data_labels_ind, \"sailboats_on_dock\", \"sailboats_on_dock\", \"sailboats_afloat\", \"powers_afloat\", \"people_visible\",\n",
    "                      # these below are the \"y values\"\n",
    "                      \"bool_people\", \"bool_sailboat_afloat\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "### Output: df_combined is a dataframe which has one column for each pixel in the images, as well as one column for each of the elements of the manual labeling from the Excel file.  It has the same number of rows as the number of rows in the Excel file, i.e. the number of labeled images.\n",
    "\n",
    "#### Approx time: 0.75-1.5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel\n",
    "df_data_labels = pd.read_excel(data_file_path, sheet_name=data_sheet_name, usecols=data_labels_to_use)\n",
    "\n",
    "# Convert data_labels_ind (the index) to string and drop rows missing index\n",
    "df_data_labels[data_labels_ind] = df_data_labels[data_labels_ind].astype(str).str.strip()\n",
    "df_data_labels = df_data_labels[df_data_labels[data_labels_ind].notna()]\n",
    "\n",
    "# Construct photo_list and photo_ids from the information in Excel\n",
    "# The images in the photo folder which should be considered all have rows in the Excel\n",
    "photo_ids  = df_data_labels[data_labels_ind].tolist()\n",
    "photo_list = [pid + \".jpg\" for pid in photo_ids]\n",
    "\n",
    "# Load images and flatten (only include those that exist)\n",
    "image_data = []\n",
    "valid_photo_ids = []\n",
    "\n",
    "# photo_ids = list of ints\n",
    "# photo_list = list of those ints with \".jpg\" at end\n",
    "for pid, photo in zip(photo_ids, photo_list):\n",
    "    try:\n",
    "        with Image.open(photo_folder_path + photo) as p:\n",
    "            gray = p.convert(\"L\")\n",
    "            flat_array = np.array(gray).flatten()\n",
    "            image_data.append(flat_array)\n",
    "            valid_photo_ids.append(pid)  # Only keep if image was successfully opened\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {photo} not found. Skipping.\")\n",
    "        \n",
    "        \n",
    "# Create DataFrame from image data\n",
    "df_images = pd.DataFrame(image_data, index=valid_photo_ids)\n",
    "\n",
    "# Create df_filtered from df_data_labels\n",
    "df_filtered = df_data_labels[df_data_labels[data_labels_ind].isin(valid_photo_ids)].copy()\n",
    "df_filtered.set_index(data_labels_ind, inplace=True)\n",
    "\n",
    "# Combine using aligned indexes\n",
    "df_combined = pd.concat([df_images, df_filtered], axis=1)\n",
    "\n",
    "# Ensure all column names are strings\n",
    "df_combined.columns = df_combined.columns.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MinMaxScaler column-wise\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_combined_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_combined),\n",
    "    columns=df_combined.columns.astype(str),\n",
    "    index=df_combined.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_combined_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models to predict the values of \"bool_people\" and \"bool_sailboat_afloat\" when seeing a new image\n",
    "- bool_people is true when there are any number of people on the dock in the image\n",
    "- bool_sailboat_afloat is true when there are any number of sailboats on the water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = [\"bool_people\", \"bool_sailboat_afloat\"]\n",
    "\n",
    "# Drop target columns before scaling\n",
    "X = df_combined.drop(columns=target_columns)\n",
    "y_people = df_combined[\"bool_people\"]\n",
    "y_sail   = df_combined[\"bool_sailboat_afloat\"]\n",
    "\n",
    "# Scale only input features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, yp_train, yp_test = train_test_split(X_scaled, y_people, test_size=0.1, random_state=42)\n",
    "_,           _,  ys_train, ys_test = train_test_split(X_scaled, y_sail,   test_size=0.1, random_state=42)\n",
    "\n",
    "# Train Models\n",
    "clf_people = RandomForestClassifier(random_state=42)\n",
    "clf_people.fit(X_train, yp_train)\n",
    "\n",
    "clf_sail = RandomForestClassifier(random_state=42)\n",
    "clf_sail.fit(X_train, ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: bool_people\n",
      "Accuracy: 0.7\n",
      "Confusion Matrix:\n",
      "[[0 2]\n",
      " [0 4]]\n",
      "\n",
      "Evaluation: bool_sailboat_afloat\n",
      "Accuracy: 0.7\n",
      "Confusion Matrix:\n",
      "[[3 2]\n",
      " [0 1]]\n",
      "\n",
      "Confusion Matrix:\n",
      "TP FN\n",
      "FP TN\n"
     ]
    }
   ],
   "source": [
    "yp_pred = clf_people.predict(X_test)\n",
    "ys_pred = clf_sail.predict(X_test)\n",
    "\n",
    "# Evaluate bool_people\n",
    "print(\"Evaluation: bool_people\")\n",
    "print(f\"Accuracy: {accuracy_score(yp_test, yp_pred):.1f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(yp_test, yp_pred))\n",
    "\n",
    "\n",
    "# Evaluate bool_sailboat_afloat\n",
    "print(\"\\nEvaluation: bool_sailboat_afloat\")\n",
    "print(f\"Accuracy: {accuracy_score(ys_test, ys_pred):.1f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ys_test, ys_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\nTP FN\\nFP TN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, scaler, input_columns):\n",
    "    \"\"\"\n",
    "    Open and preprocess a new image into a scaled feature vector.\n",
    "\n",
    "    Parameters:\n",
    "    - img_path: path to new image\n",
    "    - scaler: fitted MinMaxScaler (used only on input features)\n",
    "    - input_columns: list of columns used during training (image + metadata, but excluding targets)\n",
    "\n",
    "    Returns:\n",
    "    - Scaled DataFrame matching X input used for training\n",
    "    \"\"\"\n",
    "    with Image.open(img_path) as p:\n",
    "        gray = p.convert(\"L\")\n",
    "        flat_array = np.array(gray).flatten()\n",
    "\n",
    "    # Build DataFrame with image data (ensure correct col count)\n",
    "    df_new = pd.DataFrame([flat_array], columns=input_columns[:len(flat_array)])\n",
    "\n",
    "    # Fill any remaining Excel-origin columns with 0\n",
    "    for col in input_columns[len(flat_array):]:\n",
    "        df_new[col] = 0\n",
    "\n",
    "    df_new = df_new[input_columns]  # ensure order\n",
    "    df_new_scaled = pd.DataFrame(scaler.transform(df_new), columns=df_new.columns)\n",
    "\n",
    "    return df_new_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1400: bool_people = 1, bool_sailboat_afloat = 1\n",
      "Prediction 1407: bool_people = 1, bool_sailboat_afloat = 1\n",
      "Prediction 1419: bool_people = 1, bool_sailboat_afloat = 0\n",
      "Prediction 1428: bool_people = 1, bool_sailboat_afloat = 0\n",
      "Prediction 1658: bool_people = 1, bool_sailboat_afloat = 1\n",
      "Prediction 1702: bool_people = 1, bool_sailboat_afloat = 1\n",
      "Prediction 1727: bool_people = 1, bool_sailboat_afloat = 1\n",
      "Prediction 1759: bool_people = 0, bool_sailboat_afloat = 0\n"
     ]
    }
   ],
   "source": [
    "new_imgs = [\"1400\", \"1407\", \"1419\", \"1428\", \"1658\", \"1702\", \"1727\", \"1759\"]\n",
    "\n",
    "for i in new_imgs:\n",
    "    # Path to new image\n",
    "    new_image_path = \"./data/20230912/\" + i + \".jpg\"\n",
    "\n",
    "    input_columns = X.columns.tolist()  # X already excludes target columns\n",
    "\n",
    "    # Preprocess i\n",
    "    df_new_scaled = preprocess_image(new_image_path, scaler, input_columns)\n",
    "\n",
    "    # Predict\n",
    "    pred_people = clf_people.predict(df_new_scaled)[0]\n",
    "    pred_sail   = clf_sail.predict(df_new_scaled)[0]\n",
    "\n",
    "    print(f\"Prediction {i}: bool_people = {pred_people}, bool_sailboat_afloat = {pred_sail}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image, People, Sailboat ... Prediction\n",
    "# 1400, 1, 0 ... 1, 1 ... x\n",
    "# 1407, 0, 0 ... 1, 1 ... x\n",
    "# 1419, 1, 0 ... 1, 0 ... good\n",
    "# 1428, 0, 0 ... 1, 1 ... x\n",
    "# 1658, 1, 0 ... 1, 1 ... x\n",
    "# 1702, 1, 1 ... 1, 1 ... good\n",
    "# 1727, 1, 1 ... 1, 1 ... good\n",
    "# 1759, 1, 1 ... 1, 0 ... x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
